{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ChristofHenkel/household_image_classification/blob/master/Xception_LSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "O0ktMEmWkz4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Installing requirements"
      ]
    },
    {
      "metadata": {
        "id": "3I5SgZQ1pioi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc980238-2111-4641-da6a-2d2debf55ae3"
      },
      "cell_type": "code",
      "source": [
        "VALID_ID = '1P45QJN_Yd2PKFCE_9922jdvVVDd-XIyQ'\n",
        "CHUNK_IDS = ['1P6YTpC6ioXze2cAB0Rz2umxGd27DxtO4',\n",
        "             '1DXVqFuVn51Qa64qNfHfCSruRRfrl8MN6',\n",
        "             '1EjC0thAMzsP815v5647tBMVMyVlgerwr',\n",
        "             '1A_kHfHOn8EhEBNsGUniUe0IkNYKXImA7',\n",
        "             '1zRVyfi7l5nGNCLimjorW03gk2VhB_LAo',\n",
        "             '1H1sQPWUUTjPWGtcN5EJYKO_rmYVYH1KL'\n",
        "            ]\n",
        "CLIENT_SECRETS_ID = '1sShAACG19QKYvFk5fuD5DzmWzrKtF11-'\n",
        "CALLBACKS_ID = '19GCUwlQU9ofdTqsgPrT0oC3djOtn-nGr'\n",
        "YAML_FILE_ID = '1wQshZQ-tywmBWFlhAbc5WFPn9HrCIgOF'\n",
        "BEST_MODEL_ID = '11SqL318CF7NV5J-YqRJsueIVW8OQltu7'\n",
        "!pip install -U -q PyDrive\n",
        "#!pip install keras\n",
        "!pip install tqdm\n",
        "#!mkdir train\n",
        "#!mkdir valid\n",
        "\n",
        "import os\n",
        "import gzip\n",
        "import pickle\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zGqhzQgARMhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6990e403-15f6-48f4-aec5-d2c9f9f45d8f"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  valid\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BmP_14ATkSnV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#file = drive.CreateFile({'id': CLIENT_SECRETS_ID})\n",
        "#file.GetContentFile('client_secrets.json')\n",
        "settings = drive.CreateFile({'id': YAML_FILE_ID})\n",
        "settings.GetContentFile('settings.yaml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXGJM65L1cJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_file = drive.CreateFile({'id': VALID_ID})\n",
        "valid_file.GetContentFile('valid.zip')\n",
        "!unzip valid.zip\n",
        "!rm valid.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3L73X114qFLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def exchange_train_chunk(chunk_ind):\n",
        "  print('exchange train chunk with chunk %s'%chunk_ind)\n",
        "  if os.path.exists(\"train\"):\n",
        "    shutil.rmtree('train')\n",
        "  train_file = drive.CreateFile({'id': CHUNK_IDS[chunk_ind]})\n",
        "  train_file.GetContentFile('train.zip')\n",
        "  with zipfile.ZipFile(\"train.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall('train')\n",
        "  os.remove('train.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WhFkI_QWrD7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fe764bd-bebf-4762-bbfa-e800bf0c71dc"
      },
      "cell_type": "code",
      "source": [
        "tic = time.time()\n",
        "exchange_train_chunk(0)\n",
        "toc = time.time()\n",
        "print(toc-tic)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exchange train chunk with chunk 0\n",
            "73.4421055316925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "07DpUjt9sLKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.xception import Xception\n",
        "from keras.layers import Dropout, Dense, TimeDistributed, SpatialDropout1D, Bidirectional, CuDNNLSTM\n",
        "from keras.metrics import top_k_categorical_accuracy\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint, Callback,ReduceLROnPlateau\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "\n",
        "def top1_loss(y_true,y_pred):\n",
        "    return 1- top_k_categorical_accuracy(y_true,y_pred,k=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWTUvTvefSRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bda0455-0c0a-4ce9-e9ad-46621d360e3c"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                    vertical_flip=True,\n",
        "                                    rotation_range=20,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    shear_range=0.2\n",
        "                                    )\n",
        "\n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                                    \n",
        "                                    )\n",
        "valid_generator = train_data_gen.flow_from_directory(directory='valid',\n",
        "                             target_size=(224,224),\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                             class_mode='categorical')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6309 images belonging to 128 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "olO2ASUcMQ0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "base_model = Xception(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
        "inp = base_model.output\n",
        "main = TimeDistributed(Bidirectional(CuDNNLSTM(256)))(inp)\n",
        "main = SpatialDropout1D(0.4)(main)\n",
        "main = Bidirectional(CuDNNLSTM(256))(main)\n",
        "main = Dropout(0.4)(main)\n",
        "predictions = Dense(128,activation='softmax',kernel_regularizer=regularizers.l2(0.0001))(main)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "#model.summary()\n",
        "model.compile(optimizer=Adam(lr = 0.00003), loss='categorical_crossentropy',metrics=[top1_loss])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DpBbAdEFzHN0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "check_point = ModelCheckpoint('best_model.hdf5', monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "early_stop = EarlyStopping(patience=4)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=2, min_lr=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWjrE_aCdNnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cc2c01c6-ff8c-4d33-8c16-f80e335c752e"
      },
      "cell_type": "code",
      "source": [
        "init = model.fit_generator(valid_generator,\n",
        "                        #steps_per_epoch=train_generator.classes.size//BATCH_SIZE,\n",
        "                        steps_per_epoch=1,\n",
        "                        epochs=1,\n",
        "                        validation_data=valid_generator,\n",
        "                        validation_steps=1,\n",
        "                        verbose=1,\n",
        "                        callbacks = [check_point,early_stop,reduce_lr]\n",
        "                       )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1/1 [==============================] - 11s 11s/step - loss: 5.4070 - top1_loss: 1.0000 - val_loss: 5.0684 - val_top1_loss: 1.0000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 5.06837, saving model to best_model.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s1hhmcelYfWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_model = drive.CreateFile({'id': BEST_MODEL_ID})\n",
        "best_model.GetContentFile('best_model.hdf5')\n",
        "callbacks = drive.CreateFile({'id': CALLBACKS_ID})\n",
        "callbacks.GetContentFile('callbacks.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNUeet7yRb27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('best_model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iC5RW28o4WUk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_callbacks():\n",
        "  cb_dict = {'check_point':{'epochs_since_last_save':check_point.epochs_since_last_save,\n",
        "                            'best':check_point.best},\n",
        "            'early_stop':{'best':early_stop.best,'wait':early_stop.wait},\n",
        "            'reduce_lr':{'lr':float(K.get_value(model.optimizer.lr))}}\n",
        "  with open('callbacks.p','wb') as f:\n",
        "    pickle.dump(cb_dict,f)\n",
        "    \n",
        "def load_callbacks():\n",
        "  with open('callbacks.p','rb') as f:\n",
        "    cb_dict = pickle.load(f)\n",
        "  check_point.best = cb_dict['check_point']['best']\n",
        "  check_point.epochs_since_last_save = cb_dict['check_point']['epochs_since_last_save']\n",
        "  early_stop.best = cb_dict['early_stop']['best']\n",
        "  early_stop.wait = cb_dict['early_stop']['wait']\n",
        "  K.set_value(model.optimizer.lr,cb_dict['reduce_lr']['lr'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kp5ByjvYajui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "load_callbacks()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHhsJfjBduMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04c48f81-9220-493f-b51a-82c5399e1446"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model.hdf5  callbacks.p  datalab  settings.yaml  train  valid\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tIYt5vIo4jZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "f1b7f8fa-12c8-45e3-9da7-eff8e7a9d9f1"
      },
      "cell_type": "code",
      "source": [
        "histories = []\n",
        "for epoch in range(30):\n",
        "  for c,chunk_id in enumerate(CHUNK_IDS):\n",
        "    if gauth.access_token_expired:\n",
        "    # Refresh them if expired\n",
        "      gauth.Refresh()\n",
        "    exchange_train_chunk(c)\n",
        "    train_generator = train_data_gen.flow_from_directory(directory='train/chunk%s'%c +'/',\n",
        "                             target_size=(224,224),\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                             class_mode='categorical')\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=train_generator.classes.size//BATCH_SIZE,\n",
        "                        #steps_per_epoch=100,\n",
        "                        epochs=1,\n",
        "                        validation_data=valid_generator,\n",
        "                        validation_steps=valid_generator.classes.size//BATCH_SIZE,\n",
        "                        #validation_steps=10,\n",
        "                        verbose=1,\n",
        "                        callbacks = [check_point,early_stop,reduce_lr]\n",
        "                       )\n",
        "    save_callbacks()\n",
        "    if check_point.epochs_since_last_save == 0:\n",
        "      if gauth.access_token_expired:\n",
        "        # Refresh them if expired\n",
        "        gauth.Refresh()\n",
        "      uploaded = drive.CreateFile({'id': BEST_MODEL_ID})\n",
        "      uploaded.SetContentFile('best_model.hdf5')\n",
        "      print('uploading model')\n",
        "      uploaded.Upload()\n",
        "      uploaded = drive.CreateFile({'id': CALLBACKS_ID})\n",
        "      uploaded.SetContentFile('callbacks.p')\n",
        "      print('uploading callback data')\n",
        "      uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exchange train chunk with chunk 0\n",
            "Found 28000 images belonging to 128 classes.\n",
            "Epoch 1/1\n",
            " 557/1750 [========>.....................] - ETA: 14:00 - loss: 4.7031 - top1_loss: 0.9440"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1749/1750 [============================>.] - ETA: 0s - loss: 3.8466 - top1_loss: 0.8119"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1750/1750 [==============================] - 1383s 791ms/step - loss: 3.8458 - top1_loss: 0.8118 - val_loss: 2.6719 - val_top1_loss: 0.6401\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.67188, saving model to best_model.hdf5\n",
            "uploading model\n",
            "uploading callback data\n",
            "exchange train chunk with chunk 1\n",
            "Found 28000 images belonging to 128 classes.\n",
            "Epoch 1/1\n",
            " 183/1750 [==>...........................] - ETA: 18:02 - loss: 2.6440 - top1_loss: 0.6226"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1749/1750 [============================>.] - ETA: 0s - loss: 2.3134 - top1_loss: 0.5626"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1750/1750 [==============================] - 1373s 785ms/step - loss: 2.3132 - top1_loss: 0.5626 - val_loss: 1.9251 - val_top1_loss: 0.5010\n",
            "\n",
            "Epoch 00001: val_loss improved from 2.67188 to 1.92507, saving model to best_model.hdf5\n",
            "uploading model\n",
            "uploading callback data\n",
            "exchange train chunk with chunk 2\n",
            "Found 28000 images belonging to 128 classes.\n",
            "Epoch 1/1\n",
            " 181/1750 [==>...........................] - ETA: 17:58 - loss: 2.0270 - top1_loss: 0.5148"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1749/1750 [============================>.] - ETA: 0s - loss: 1.8477 - top1_loss: 0.4691"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1750/1750 [==============================] - 1374s 785ms/step - loss: 1.8477 - top1_loss: 0.4691 - val_loss: 1.6166 - val_top1_loss: 0.4326\n",
            "\n",
            "Epoch 00001: val_loss improved from 1.92507 to 1.61662, saving model to best_model.hdf5\n",
            "uploading model\n",
            "uploading callback data\n",
            "exchange train chunk with chunk 3\n",
            "Found 28000 images belonging to 128 classes.\n",
            "Epoch 1/1\n",
            " 181/1750 [==>...........................] - ETA: 18:05 - loss: 1.6974 - top1_loss: 0.4454"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1520/1750 [=========================>....] - ETA: 2:38 - loss: 1.6331 - top1_loss: 0.4229"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yEr7YFOW3oUh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TODOS:\n",
        "Continue training:\n",
        "  model file -> easy\n",
        "\n",
        "*   save callbacks\n",
        "*   save history\n",
        "\n"
      ]
    }
  ]
}